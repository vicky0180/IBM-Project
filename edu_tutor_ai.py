# -*- coding: utf-8 -*-
"""edu tutor ai

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15bFnfBkWatT26lU7DVD2oSXiWTjKeWI3
"""

!pip install transformers torch gradio -q
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import gradio as gr
# Choose the Granite model
model_id = "ibm-granite/granite-3.2-2b-instruct"

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id)

# Create a text generator pipeline
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
def tutor_ai(user_input, task):
    if task == "Explain a Concept":
        prompt = f"Explain the concept of {user_input} in simple words."
    elif task == "Generate Quiz":
        prompt = f"Create 3 simple quiz questions about {user_input} with answers."
    else:
        prompt = user_input

    output = generator(prompt, max_length=200, do_sample=True, temperature=0.7)
    return output[0]['generated_text']
demo = gr.Interface(
    fn=tutor_ai,
    inputs=[
        gr.Textbox(label="Enter Topic"),
        gr.Radio(["Explain a Concept", "Generate Quiz"], label="Choose Task")
    ],
    outputs="text",
    title="EduTutor AI",
    description="Personalized Learning with IBM Granite"
)

# This makes it show inside Colab
demo.launch(share=True, inline=True)